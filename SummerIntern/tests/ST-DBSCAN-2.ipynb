{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "from plotly import tools\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "from utils.load_catch_from_bigquery import load_BQ_and_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own plotly user and mapbox access token\n",
    "plotly.tools.set_credentials_file(username='sollimann', api_key='Mt0jyw4YVAEzihyWlLvL')\n",
    "plotly.tools.set_config_file(world_readable=True,\n",
    "                             sharing='public')\n",
    "\n",
    "mapbox_access_token = 'pk.eyJ1Ijoic29sbGltYW5uIiwiYSI6ImNqeDYyYWVkdDAwYXM0M3QyZ3AwNDJudWUifQ.NaYqXFLNEBG1cVzAdP-GYg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST-DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import ST_DBSCAN.STDBSCAN as STDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_catch(catchLimit):\n",
    "    \n",
    "    filtered_df = df[(df['Total catch Krill - Mt'] > catchLimit)]\n",
    "    \n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(df, output_name):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    labels = df['cluster'].values\n",
    "    X = df[['Longitude', 'Latitude']].values\n",
    "\n",
    "    # Black removed and is used for noise instead.\n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each)\n",
    "              for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_member_mask = (labels == k)\n",
    "\n",
    "        xy = X[class_member_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=6)\n",
    "\n",
    "    plt.title('ST-DSCAN: #n of clusters {}'.format(len(unique_labels)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consistent_color_scaling(df):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        \n",
    "    \n",
    "    OUTPUTS:\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # total number of clusters (noise not included)\n",
    "    nr_of_clusters = df['cluster'].max()\n",
    "    \n",
    "    # all available colors https://www.color-hex.com/\n",
    "    colors = [\"#b8b8b8\", \"#2791d3\", \"#27c96d\", \"#1b5a72\", \"#eb5e55\", \"#780303\", \"#f15e75\",\"#53c4da\", \"#3b4249\",\n",
    "           \"#f7c56e\",\"#ff966c\",\"#ffed43\",\"#177e89\",\"#780303\",\"#51caf9\", \"#f7c56e\", \"#f5d4df\", \"#bee9e8\", \"#391b55\",\n",
    "              \"#c8e4d6\",]\n",
    "    \n",
    "    # add color for noise manually\n",
    "    scl = [[0.0,\"#b8b8b8\"]]\n",
    "    \n",
    "    # add additional colors for clusters\n",
    "    for i in range(1,nr_of_clusters+1):\n",
    "        index = round(i * (1.0 / nr_of_clusters),3)\n",
    "        color = [index,colors[i]]\n",
    "        scl.append(color)\n",
    "\n",
    "    return scl, colors[0:(nr_of_clusters+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(df,output_name, scl):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        \n",
    "    \n",
    "    OUTPUTS:\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # convert a column consisting of datetime64 objects to a string\n",
    "    df['DateStr'] = df['Date'].dt.strftime('%b') + ' , cluster: ' + df['cluster'].astype(str)\n",
    "\n",
    "    # Adding dateframes\n",
    "    df['text'] = df['DateStr'] + ' , ' + df['Vessel'] + ', ' + 'Catch: ' + df['Total catch Krill - Mt'].astype(str)\n",
    "           \n",
    "    # data\n",
    "    data = [\n",
    "        go.Scattermapbox(\n",
    "            lon = df['Longitude'],\n",
    "            lat = df['Latitude'],\n",
    "            text = df['text'],\n",
    "            mode='markers',\n",
    "            marker=go.scattermapbox.Marker(\n",
    "                size = 8, \n",
    "                opacity = 0.8,\n",
    "                reversescale = False,\n",
    "                autocolorscale = False,\n",
    "                colorscale = scl,\n",
    "                cmin = 0,#df['cluster'].min(),\n",
    "                color = df['cluster'],\n",
    "                cmax = df['cluster'].max(),\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Layout\n",
    "    layout = go.Layout(\n",
    "        title='catch sites',\n",
    "        autosize=True,\n",
    "        hovermode='closest',\n",
    "        showlegend=True,\n",
    "        mapbox=go.layout.Mapbox(\n",
    "            accesstoken=mapbox_access_token,\n",
    "            bearing=0,\n",
    "            center=go.layout.mapbox.Center(\n",
    "                lat=-54,\n",
    "                lon=-27\n",
    "            ),\n",
    "            pitch=0,\n",
    "            zoom=2,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Return figure\n",
    "    fig = go.Figure(data=data,layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get cluster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_catch_for_cluster(df_1):\n",
    "\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        \n",
    "    \n",
    "    OUTPUTS:\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    import calendar\n",
    "    df_2 = df_1.groupby('month').sum()\n",
    "    df_2.reset_index(inplace=True)\n",
    "    df_2['month'] = df_2['month'].apply(lambda x: calendar.month_abbr[x])\n",
    "    df_2[['month','Total catch Krill - Mt']]\n",
    "    \n",
    "    return df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_monthly_catch_from_cluster(df_cluster):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        df_clust_id = df[df['cluster' == id]]         a dataframe for a particular cluster\n",
    "    \n",
    "    OUTPUTS:\n",
    "        [catch_month.mean(), ....]   A list of average catch for each month in cluster\n",
    "    \"\"\"\n",
    "    months = []\n",
    "    df_months = df_cluster['month'].drop_duplicates()\n",
    "    df_months.index = pd.RangeIndex(len(df_months.index))\n",
    "    for m in range(0,len(df_months)):\n",
    "        mean = df_cluster[df_cluster['month'] == df_months[m]].loc[:,\"Total catch Krill - Mt\"].mean()\n",
    "        mean = int(mean) #round of\n",
    "        months.append(str(mean)+' mT')\n",
    "    return months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_hist(df):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        \n",
    "    \n",
    "    OUTPUTS:\n",
    "        \n",
    "    \"\"\"\n",
    "    import plotly.figure_factory as ff\n",
    "    hist_data = []\n",
    "    avg_catch_all_clusters = []\n",
    "    df_clust = df[df['cluster']==-1]\n",
    "    df_clust_sorted = df_clust.sort_values(by='month')\n",
    "    data = df_clust_sorted['Date'].dt.strftime('%b')\n",
    "    hist_data.append(data)\n",
    "    \n",
    "    # add average catch for cluster noise as well\n",
    "    catch = get_average_monthly_catch_from_cluster(df_clust_sorted)\n",
    "    avg_catch_all_clusters.append(catch)    \n",
    "    \n",
    "    # get data from each cluster\n",
    "    for c in range(1,max(df_clustered['cluster'])+1):\n",
    "        df_clust = df[df['cluster']==c]\n",
    "        df_clust_sorted = df_clust.sort_values(by='month')     \n",
    "        data = df_clust_sorted['Date'].dt.strftime('%b')\n",
    "        hist_data.append(data)\n",
    "        \n",
    "        # calculate mean catch per month for this cluster\n",
    "        catch = get_average_monthly_catch_from_cluster(df_clust_sorted)\n",
    "        avg_catch_all_clusters.append(catch)\n",
    "\n",
    "    # get cluster label\n",
    "    group_labels = ['noise']\n",
    "    for c in range(1,max(df_clustered['cluster'])+1):\n",
    "        group_labels.append('Cluster ' + str(c))\n",
    "\n",
    "    return avg_catch_all_clusters,hist_data, group_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = df_clustered\\ndf_clust = df[df['cluster']==c]\\ndf_clust_sorted = df_clust.sort_values(by='month')     \\ndf_clust_sorted\\n#data = df_clust_sorted['Date'].dt.strftime('%b')\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df = df_clustered\n",
    "df_clust = df[df['cluster']==c]\n",
    "df_clust_sorted = df_clust.sort_values(by='month')     \n",
    "df_clust_sorted\n",
    "#data = df_clust_sorted['Date'].dt.strftime('%b')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#def average_catch_pr_month(df_clustered):\\ndf_clust = df_clustered[df_clustered[\\'cluster\\']==-1]\\ndf_clust_sorted = df_clust.sort_values(by=\\'month\\') \\n#df_clust_sorted\\nmonths = []\\ndf_months = df_clust_sorted[\\'month\\'].drop_duplicates()\\ndf_months.index = pd.RangeIndex(len(df_months.index))\\n\\nfor m in range(0,len(df_months)):\\n    mean = df_clust_sorted[df_clust_sorted[\\'month\\'] == df_months[m]].loc[:,\"Total catch Krill - Mt\"].mean()\\n    mean = int(mean) #round of\\n    months.append(str(mean)+\\' mT\\')\\nmonths\\n#catch = get_average_monthly_catch_from_cluster(df_clust_sorted)\\n#catch\\n\\n#months = get_available_months_from_cluster(df_cluster)\\n#months\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#def average_catch_pr_month(df_clustered):\n",
    "df_clust = df_clustered[df_clustered['cluster']==-1]\n",
    "df_clust_sorted = df_clust.sort_values(by='month') \n",
    "#df_clust_sorted\n",
    "months = []\n",
    "df_months = df_clust_sorted['month'].drop_duplicates()\n",
    "df_months.index = pd.RangeIndex(len(df_months.index))\n",
    "\n",
    "for m in range(0,len(df_months)):\n",
    "    mean = df_clust_sorted[df_clust_sorted['month'] == df_months[m]].loc[:,\"Total catch Krill - Mt\"].mean()\n",
    "    mean = int(mean) #round of\n",
    "    months.append(str(mean)+' mT')\n",
    "months\n",
    "#catch = get_average_monthly_catch_from_cluster(df_clust_sorted)\n",
    "#catch\n",
    "\n",
    "#months = get_available_months_from_cluster(df_cluster)\n",
    "#months\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows and cols needed\n",
    "def subplot_rows_and_cols(size):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "       \n",
    "    \n",
    "    OUTPUTS:\n",
    "        \n",
    "    \"\"\"\n",
    "    import math\n",
    "    rows = math.ceil(np.sqrt(size))\n",
    "    cols = rows\n",
    "    return rows, cols\n",
    "\n",
    "def create_histograms(avg_catch,hist_data,group_labels, colors):\n",
    "\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        \n",
    "    \n",
    "    OUTPUTS:\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # init\n",
    "    data = []\n",
    "    layout = []\n",
    "    scl = colors     \n",
    "    \n",
    "    # add noise cluster\n",
    "    noise = go.Histogram(\n",
    "    x = hist_data[0],\n",
    "    marker=dict(\n",
    "    color=scl[0], \n",
    "    ),\n",
    "    opacity = 0.75,\n",
    "    name = 'noise',\n",
    "    text = avg_catch[0]\n",
    "    )\n",
    "    \n",
    "    # add noise to data\n",
    "    data.append(noise)\n",
    "    \n",
    "    # add all valid clusters\n",
    "    for i in range(1,len(hist_data)):\n",
    "        cluster = go.Histogram(\n",
    "            x = hist_data[i],\n",
    "            marker=dict(\n",
    "            color=scl[i],\n",
    "            ),\n",
    "            opacity = 0.75,\n",
    "            name = group_labels[i],\n",
    "            text = avg_catch[i]\n",
    "        )\n",
    "        data.append(cluster)\n",
    "    \n",
    "    # how many rows and cols do we need?\n",
    "    rows, cols = subplot_rows_and_cols(len(hist_data))\n",
    "    \n",
    "    # add clusters to figure\n",
    "    fig = tools.make_subplots(rows=rows, cols=cols)\n",
    "    \n",
    "    # subplot positions\n",
    "    # max 16 subplots\n",
    "    row = [1, 1, 2, 2, 1, 2, 3, 3, 3, 1, 2, 3, 4, 4, 4, 4]\n",
    "    col = [1, 2, 1, 2, 3, 3, 3, 2, 1, 4, 4, 4, 4, 3, 2, 1]\n",
    "    \n",
    "    for i in range(0, len(hist_data)):\n",
    "        fig.append_trace(data[i], row[i], col[i])\n",
    "        \n",
    "\n",
    "    fig['layout'].update(height=600, width=600, title='Multiple Subplots' +\n",
    "                                                      ' with Titles')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing connection to BigQuery in GCP.\n",
      "    SUCCESS: Connection to BigQuery in GCP established.\n",
      "Extracting catch data from 2010 to October 2018.\n",
      "Extracting catch data from December 2018 onwards.\n",
      "Merging and cleaning catch data\n",
      "DONE after 8.57sec: Data extracted, merged and cleaned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ua388\\Documents\\catch\\route\\ST_DBSCAN\\STDBSCAN.py:38: FutureWarning:\n",
      "\n",
      "set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "\n",
      "C:\\Users\\ua388\\Documents\\catch\\route\\ST_DBSCAN\\STDBSCAN.py:41: FutureWarning:\n",
      "\n",
      "set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "\n",
      "C:\\Users\\ua388\\Documents\\catch\\route\\ST_DBSCAN\\STDBSCAN.py:63: FutureWarning:\n",
      "\n",
      "set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "\n",
      "C:\\Users\\ua388\\Documents\\catch\\route\\ST_DBSCAN\\STDBSCAN.py:34: FutureWarning:\n",
      "\n",
      "set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    # Get data\n",
    "    df = load_BQ_and_clean()\n",
    "    \n",
    "    # remove bad catch\n",
    "    df = filter_catch(100)\n",
    "    \n",
    "    # create month\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    \n",
    "    # re-index\n",
    "    df.index = pd.RangeIndex(len(df.index))\n",
    "    \n",
    "    \n",
    "    spatial_threshold = 10 # km\n",
    "    temporal_threshold = 1 # months\n",
    "    min_neighbors = 17\n",
    "    df_clustered = STDBSCAN.ST_DBSCAN(df, spatial_threshold, temporal_threshold, min_neighbors)\n",
    "    scl, colors = get_consistent_color_scaling(df_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_clusters(df_clustered, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ua388\\AppData\\Local\\Continuum\\anaconda3\\envs\\py37\\lib\\site-packages\\IPython\\core\\display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sollimann/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = visualize_data(df_clustered,'clustered_plot', scl)\n",
    "py.iplot(fig, filename='catch-sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]    [ (1,2) x2,y2 ]    [ (1,3) x3,y3 ]    [ (1,4) x4,y4 ]  \n",
      "[ (2,1) x5,y5 ]    [ (2,2) x6,y6 ]    [ (2,3) x7,y7 ]    [ (2,4) x8,y8 ]  \n",
      "[ (3,1) x9,y9 ]    [ (3,2) x10,y10 ]  [ (3,3) x11,y11 ]  [ (3,4) x12,y12 ]\n",
      "[ (4,1) x13,y13 ]  [ (4,2) x14,y14 ]  [ (4,3) x15,y15 ]  [ (4,4) x16,y16 ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ua388\\AppData\\Local\\Continuum\\anaconda3\\envs\\py37\\lib\\site-packages\\IPython\\core\\display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sollimann/32.embed\" height=\"600px\" width=\"600px\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cluster_catch,hist_data, group_labels = cluster_hist(df_clustered)\n",
    "avg_cluster_catch\n",
    "fig = create_histograms(avg_cluster_catch,hist_data, group_labels, colors)\n",
    "py.iplot(fig, filename='make-subplots-multiple-with-titles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = df_clustered.to_csv (r'C:\\Users\\ua388\\Documents\\export_dataframe.csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
